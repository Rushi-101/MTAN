{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MTAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq84ytot8rC1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8bfb6f-19af-43b6-fa9d-200dcf271550"
      },
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQpoAgKd1QQ8"
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/biplab project')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7MXNyc1OG5E"
      },
      "source": [
        "!unzip /content/drive/MyDrive/nyuv2.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io8aV2ek34Qz"
      },
      "source": [
        "from create_dataset import *\n",
        "from utils import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc1U0ZwX8ueW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "9bfed1fb-c05d-4a85-d5bc-dbbcd5f4ba45"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "import torch.utils.data.sampler as sampler\n",
        "import numpy as np\n",
        "from create_dataset import *\n",
        "from utils import *\n",
        "\n",
        "\n",
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SegNet, self).__init__()\n",
        "        # initialise network parameters\n",
        "        filter = [64, 128, 256, 512, 512]\n",
        "        self.class_nb = 13\n",
        "\n",
        "        # define encoder decoder layers\n",
        "        self.encoder_block = nn.ModuleList([self.conv_layer([3, filter[0]])])\n",
        "        self.decoder_block = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        for i in range(4):\n",
        "            self.encoder_block.append(self.conv_layer([filter[i], filter[i + 1]]))\n",
        "            self.decoder_block.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "\n",
        "        # define convolution layer\n",
        "        self.conv_block_enc = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        self.conv_block_dec = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "        for i in range(4):\n",
        "            if i == 0:\n",
        "                self.conv_block_enc.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "                self.conv_block_dec.append(self.conv_layer([filter[i], filter[i]]))\n",
        "            else:\n",
        "                self.conv_block_enc.append(nn.Sequential(self.conv_layer([filter[i + 1], filter[i + 1]]),\n",
        "                                                         self.conv_layer([filter[i + 1], filter[i + 1]])))\n",
        "                self.conv_block_dec.append(nn.Sequential(self.conv_layer([filter[i], filter[i]]),\n",
        "                                                         self.conv_layer([filter[i], filter[i]])))\n",
        "\n",
        "        # define task attention layers\n",
        "        self.encoder_att = nn.ModuleList([nn.ModuleList([self.att_enc_layer([filter[0], filter[0], filter[0]])])])\n",
        "        self.decoder_att = nn.ModuleList([nn.ModuleList([self.att_layer([2 * filter[0], filter[0], filter[0]])])])\n",
        "        self.encoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[1]])])\n",
        "        self.decoder_block_att = nn.ModuleList([self.conv_layer([filter[0], filter[0]])])\n",
        "\n",
        "        for j in range(3):\n",
        "            if j < 2:\n",
        "                self.encoder_att.append(nn.ModuleList([self.att_enc_layer([filter[0], filter[0], filter[0]])]))\n",
        "                self.decoder_att.append(nn.ModuleList([self.att_layer([2 * filter[0], filter[0], filter[0]])]))\n",
        "            for i in range(4):\n",
        "                self.encoder_att[j].append(self.att_enc_layer([2 * filter[i + 1], filter[i + 1], filter[i + 1]]))\n",
        "                self.decoder_att[j].append(self.att_layer([filter[i + 1] + filter[i], filter[i], filter[i]]))\n",
        "\n",
        "        for i in range(4):\n",
        "            if i < 3:\n",
        "                self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 2]]))\n",
        "                self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i]]))\n",
        "            else:\n",
        "                self.encoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "                self.decoder_block_att.append(self.conv_layer([filter[i + 1], filter[i + 1]]))\n",
        "\n",
        "        self.pred_task1 = self.conv_layer([filter[0], self.class_nb], pred=True)\n",
        "        self.pred_task2 = self.conv_layer([filter[0], 1], pred=True)\n",
        "        self.pred_task3 = self.conv_layer([filter[0], 3], pred=True)\n",
        "\n",
        "        # define pooling and unpooling functions\n",
        "        self.down_sampling = nn.MaxPool2d(kernel_size=2, stride=2, return_indices=True)\n",
        "        self.up_sampling = nn.MaxUnpool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.logsigma = nn.Parameter(torch.FloatTensor([-0.5, -0.5, -0.5]))\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_normal_(m.weight)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def conv_layer(self, channel, pred=False):\n",
        "        if not pred:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=3, padding=1),\n",
        "                nn.BatchNorm2d(num_features=channel[1]),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "        else:\n",
        "            conv_block = nn.Sequential(\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[0], kernel_size=3, padding=1),\n",
        "                nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            )\n",
        "        return conv_block\n",
        "\n",
        "    def att_layer(self, channel):\n",
        "        att_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[2]),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "        return att_block\n",
        "\n",
        "    def att_enc_layer(self, channel):\n",
        "        att_block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=channel[0], out_channels=channel[1], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[1]),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(in_channels=channel[1], out_channels=channel[2], kernel_size=1, padding=0),\n",
        "            nn.BatchNorm2d(channel[2]),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        return att_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        g_encoder, g_decoder, g_maxpool, g_upsampl, indices = ([0] * 5 for _ in range(5))\n",
        "        for i in range(5):\n",
        "            g_encoder[i], g_decoder[-i - 1] = ([0] * 2 for _ in range(2))\n",
        "\n",
        "        # define attention list for task\n",
        "        atten_encoder, atten = ([0] * 5 for _ in range(2))\n",
        "        for i in range(5):\n",
        "            atten_encoder[i], atten[i] = ([0] * 2 for _ in range(2)) \n",
        "\n",
        "\n",
        "        atten, atten_decoder = ([0] * 3 for _ in range(2))\n",
        "        for i in range(3):\n",
        "            atten[i], atten_decoder[i] = ([0] * 5 for _ in range(2))\n",
        "        for i in range(3):\n",
        "            for j in range(5):\n",
        "                atten[i][j], atten_decoder[i][j] = ([0] * 3 for _ in range(2))\n",
        "    \n",
        "        # define global shared network\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_encoder[i][0] = self.encoder_block[i](x)\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "            else:\n",
        "                g_encoder[i][0] = self.encoder_block[i](g_maxpool[i - 1])\n",
        "                g_encoder[i][1] = self.conv_block_enc[i](g_encoder[i][0])\n",
        "                g_maxpool[i], indices[i] = self.down_sampling(g_encoder[i][1])\n",
        "\n",
        "        for i in range(5):\n",
        "            if i == 0:\n",
        "                g_upsampl[i] = self.up_sampling(g_maxpool[-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "            else:\n",
        "                g_upsampl[i] = self.up_sampling(g_decoder[i - 1][-1], indices[-i - 1])\n",
        "                g_decoder[i][0] = self.decoder_block[-i - 1](g_upsampl[i])\n",
        "                g_decoder[i][1] = self.conv_block_dec[-i - 1](g_decoder[i][0])\n",
        "\n",
        "       #output channels = 64\n",
        "       \n",
        "        # define task dependent attention module\n",
        "        \n",
        "      \n",
        "        for j in range(5):\n",
        "            if j == 0:\n",
        "                atten_encoder[j][0] = self.encoder_att[0][j](g_encoder[j][0])\n",
        "                #atten_encoder[j][1] = (atten_encoder[j][0]) * g_encoder[j][1]\n",
        "                atten_encoder[j][1] = self.encoder_block_att[j](atten_encoder[j][0])\n",
        "                atten_encoder[j][1] = F.max_pool2d(atten_encoder[j][1], kernel_size=2, stride=2)\n",
        "            else:\n",
        "                atten_encoder[j][0] = self.encoder_att[0][j](torch.cat((g_encoder[j][0], atten_encoder[j - 1][1]), dim=1))\n",
        "                #atten_encoder[j][1] = (atten_encoder[j][0]) * g_encoder[j][1]\n",
        "                atten_encoder[j][1] = self.encoder_block_att[j](atten_encoder[j][0])\n",
        "                atten_encoder[j][1] = F.max_pool2d(atten_encoder[j][1], kernel_size=2, stride=2)\n",
        "\n",
        "        for i in range(3):       \n",
        "            for j in range(5):\n",
        "                if j == 0:\n",
        "                    atten_decoder[i][j][0] = F.interpolate(atten_encoder[-1][-1], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "                    atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "                    atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "                    atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "                else:\n",
        "                    atten_decoder[i][j][0] = F.interpolate(atten_decoder[i][j - 1][2], scale_factor=2, mode='bilinear', align_corners=True)\n",
        "                    atten_decoder[i][j][0] = self.decoder_block_att[-j - 1](atten_decoder[i][j][0])\n",
        "                    atten_decoder[i][j][1] = self.decoder_att[i][-j - 1](torch.cat((g_upsampl[j], atten_decoder[i][j][0]), dim=1))\n",
        "                    atten_decoder[i][j][2] = (atten_decoder[i][j][1]) * g_decoder[j][-1]\n",
        "      \n",
        "        # define task prediction layers\n",
        "        t1_pred = F.log_softmax(self.pred_task1(atten_decoder[0][-1][-1]), dim=1)\n",
        "        t2_pred = self.pred_task2(atten_decoder[1][-1][-1])\n",
        "        t3_pred = self.pred_task3(atten_decoder[2][-1][-1])\n",
        "        t3_pred = t3_pred / torch.norm(t3_pred, p=2, dim=1, keepdim=True)\n",
        "\n",
        "        return [t1_pred, t2_pred, t3_pred], self.logsigma\n",
        "\n",
        "\n",
        "# define model, optimiser and scheduler\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "SegNet_MTAN = SegNet().to(device)\n",
        "optimizer = optim.Adam(SegNet_MTAN.parameters(), lr=1e-4)\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
        "\n",
        "print('Parameter Space: ABS: {:.1f}, REL: {:.4f}'.format(count_parameters(SegNet_MTAN),\n",
        "                                                         count_parameters(SegNet_MTAN) / 24981069))\n",
        "print('LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30')\n",
        "\n",
        "# define dataset\n",
        "dataset_path = '.'\n",
        "if True:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True, augmentation=True)\n",
        "    print('Applying data augmentation on NYUv2.')\n",
        "else:\n",
        "    nyuv2_train_set = NYUv2(root=dataset_path, train=True)\n",
        "    print('Standard training strategy without data augmentation.')\n",
        "\n",
        "nyuv2_test_set = NYUv2(root=dataset_path, train=False)\n",
        "\n",
        "batch_size = 2\n",
        "nyuv2_train_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True)\n",
        "\n",
        "nyuv2_test_loader = torch.utils.data.DataLoader(\n",
        "    dataset=nyuv2_test_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "print(device)\n",
        "# Train and evaluate multi-task network\n",
        "#SegNet_MTAN = torch.load('/content/drive/My Drive/biplab sir project/multi_task_model.pt')\n",
        "multi_task_trainer(nyuv2_train_loader,\n",
        "                   nyuv2_test_loader,\n",
        "                   SegNet_MTAN,\n",
        "                   device,\n",
        "                   optimizer,\n",
        "                   scheduler,\n",
        "                   20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameter Space: ABS: 44229076.0, REL: 1.7705\n",
            "LOSS FORMAT: SEMANTIC_LOSS MEAN_IOU PIX_ACC | DEPTH_LOSS ABS_ERR REL_ERR | NORMAL_LOSS MEAN MED <11.25 <22.5 <30\n",
            "Applying data augmentation on NYUv2.\n",
            "cuda:0\n",
            "Epoch: 0000 | TRAIN: 1.9650 0.0719 0.3318 | 0.8777 0.8777 0.4199 | 0.3597 46.6216 44.8142 0.0378 0.1389 0.2417 ||TEST: 1.7891 0.1037 0.3844 | 0.9282 0.9282 0.3300 | 0.3248 44.0575 42.4706 0.0425 0.1537 0.2718 \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-d519145ce407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    233\u001b[0m                    \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                    \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                    20)\n\u001b[0m",
            "\u001b[0;32m/content/drive/My Drive/biplab project/utils.py\u001b[0m in \u001b[0;36mmulti_task_trainer\u001b[0;34m(train_loader, test_loader, multi_task_model, device, optimizer, scheduler, total_epoch)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mconf_mat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_task_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_nb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mtrain_depth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_depth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_normal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/My Drive/biplab project/create_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;31m# load data from the pre-processed npy files\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/image/{:d}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0msemantic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/label/{:d}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/depth/{:d}.npy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    424\u001b[0m         \u001b[0;31m# If the file size is less than N, we need to make sure not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;31m# to seek past the beginning of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m         \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# back-up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    427\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ZIP_SUFFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0;31m# zip-file (assume .npz)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_h0O375Kru7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}